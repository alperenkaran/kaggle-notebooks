{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/alperenkaran/titanic-with-clear-explanations?scriptVersionId=88886040\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown","outputs":[],"execution_count":0},{"cell_type":"markdown","source":"### Libraries","metadata":{}},{"cell_type":"code","source":"import numpy as np; np.set_printoptions(suppress=True) # suppress scientific notation\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom tqdm.auto import tqdm #create progress bars\n\n# preprocessing\nfrom sklearn.preprocessing import MinMaxScaler\n\n# learning algorithms\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\n\n# cross validation\nfrom sklearn.model_selection import GridSearchCV","metadata":{"execution":{"iopub.status.busy":"2021-06-27T18:05:58.691457Z","iopub.execute_input":"2021-06-27T18:05:58.691876Z","iopub.status.idle":"2021-06-27T18:05:59.193344Z","shell.execute_reply.started":"2021-06-27T18:05:58.691793Z","shell.execute_reply":"2021-06-27T18:05:59.192313Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Section 1: First look at the data","metadata":{}},{"cell_type":"markdown","source":"We load the train.csv and test.csv files","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv('../input/titanic/train.csv')\ntest = pd.read_csv('../input/titanic/test.csv')","metadata":{"execution":{"iopub.status.busy":"2021-06-27T18:05:59.195368Z","iopub.execute_input":"2021-06-27T18:05:59.195797Z","iopub.status.idle":"2021-06-27T18:05:59.211481Z","shell.execute_reply.started":"2021-06-27T18:05:59.195737Z","shell.execute_reply":"2021-06-27T18:05:59.210765Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's look at sample 3 rows from `train` and `test`:","metadata":{}},{"cell_type":"code","source":"train.sample(3)","metadata":{"execution":{"iopub.status.busy":"2021-06-27T18:05:59.212817Z","iopub.execute_input":"2021-06-27T18:05:59.213092Z","iopub.status.idle":"2021-06-27T18:05:59.234567Z","shell.execute_reply.started":"2021-06-27T18:05:59.213065Z","shell.execute_reply":"2021-06-27T18:05:59.233795Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.sample(3)","metadata":{"execution":{"iopub.status.busy":"2021-06-27T18:05:59.235793Z","iopub.execute_input":"2021-06-27T18:05:59.236086Z","iopub.status.idle":"2021-06-27T18:05:59.250551Z","shell.execute_reply.started":"2021-06-27T18:05:59.23606Z","shell.execute_reply":"2021-06-27T18:05:59.249618Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The `train` data contains an extra column `Survived` which constitute the labels for supervised learning.\n\nBelow we write that column to a variable `y_train`, and other columns of `train` to a variable called `x_train`. For consistency, we rename `test` as `x_test`. Our ultimate goal is to find `y_test`, that is, the labels corresponding to `x_test`.","metadata":{}},{"cell_type":"code","source":"y_train = train['Survived']\nx_train = train.drop('Survived', 1)\nx_test = test","metadata":{"execution":{"iopub.status.busy":"2021-06-27T18:05:59.253567Z","iopub.execute_input":"2021-06-27T18:05:59.254023Z","iopub.status.idle":"2021-06-27T18:05:59.262731Z","shell.execute_reply.started":"2021-06-27T18:05:59.253991Z","shell.execute_reply":"2021-06-27T18:05:59.261691Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Section 2: Handling missing data","metadata":{}},{"cell_type":"markdown","source":"Let's now look at the frequency and percentage of missing values in `train` and `test`.","metadata":{}},{"cell_type":"code","source":"train_missing_count = x_train.isnull().sum()\ntrain_missing_percent = (x_train.isnull().mean()*100).round(2)\ntest_missing_count = x_test.isnull().sum()\ntest_missing_percent = (x_test.isnull().mean()*100).round(2)\n\nmissing_info = pd.concat([train_missing_count, train_missing_percent, test_missing_count, test_missing_percent], axis = 1)\nmissing_info.columns = ['train missing counts', 'train missing percentage', 'test missing count', 'test missing percentage']\nmissing_info.sort_values('train missing counts', ascending = False)","metadata":{"execution":{"iopub.status.busy":"2021-06-27T18:05:59.26482Z","iopub.execute_input":"2021-06-27T18:05:59.265259Z","iopub.status.idle":"2021-06-27T18:05:59.30083Z","shell.execute_reply.started":"2021-06-27T18:05:59.265219Z","shell.execute_reply":"2021-06-27T18:05:59.299798Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are missing data in `Cabin`, `Age`,`Embarked` and `Fare` columns. We will handle them separately below.","metadata":{}},{"cell_type":"markdown","source":"### 2.1 The `Cabin` feature\n\nThe `Cabin` information is missing in approximately 78% of the `x_train` and `x_test` sets. Let's look at the unique non-nan values in `x_train`.","metadata":{}},{"cell_type":"code","source":"x_train['Cabin'].unique()","metadata":{"execution":{"iopub.status.busy":"2021-06-27T18:05:59.302656Z","iopub.execute_input":"2021-06-27T18:05:59.303044Z","iopub.status.idle":"2021-06-27T18:05:59.310125Z","shell.execute_reply.started":"2021-06-27T18:05:59.303004Z","shell.execute_reply":"2021-06-27T18:05:59.309278Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As shown above, the `Cabin` column contains many unique values. So, it may be a good idea to remove this feature from further analyses. Below we delete this column from `x_train` and `x_test` data.","metadata":{}},{"cell_type":"code","source":"x_train = x_train.drop('Cabin', 1)\nx_test = x_test.drop('Cabin', 1)","metadata":{"execution":{"iopub.status.busy":"2021-06-27T18:05:59.311319Z","iopub.execute_input":"2021-06-27T18:05:59.31156Z","iopub.status.idle":"2021-06-27T18:05:59.322614Z","shell.execute_reply.started":"2021-06-27T18:05:59.311538Z","shell.execute_reply":"2021-06-27T18:05:59.321625Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2.2 The `Embarked` feature\n\nFor this feature, there are only 2 missing values in the `x_train` data, and no missing values in `x_test`. Let's look at them:","metadata":{}},{"cell_type":"code","source":"x_train[x_train['Embarked'].isnull()]","metadata":{"execution":{"iopub.status.busy":"2021-06-27T18:05:59.323802Z","iopub.execute_input":"2021-06-27T18:05:59.324054Z","iopub.status.idle":"2021-06-27T18:05:59.344753Z","shell.execute_reply.started":"2021-06-27T18:05:59.32403Z","shell.execute_reply":"2021-06-27T18:05:59.343821Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"To fill in the two missing `Embarked` values, let's look at the frequency table of this feature below.","metadata":{}},{"cell_type":"code","source":"embarked_freq = x_train['Embarked'].value_counts().rename('Embarked frequency')\nembarked_percent = (x_train['Embarked'].value_counts(normalize = True)*100).round(2).rename('Embarked percent')\npd.concat([embarked_freq,embarked_percent], axis = 1)","metadata":{"execution":{"iopub.status.busy":"2021-06-27T18:05:59.346326Z","iopub.execute_input":"2021-06-27T18:05:59.346644Z","iopub.status.idle":"2021-06-27T18:05:59.367668Z","shell.execute_reply.started":"2021-06-27T18:05:59.346614Z","shell.execute_reply":"2021-06-27T18:05:59.366748Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The table above shows that about 72% of the data have `Embarked` value of `S`. However, it is still possible that the frequencies change with respect to other features. For instance, it is possible that most females embarked from not `S` but `C`. \n\nLet's see whether the frequency of `Embarked` feature differs with respect to some other features:","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(1,4, figsize=(14,4))\nfor i,colname in enumerate(['Sex','Pclass','Parch','SibSp']):\n    sns.countplot(data=x_train, x=colname, hue='Embarked', ax=ax[i]).set_title('Freq. of Embarked w.r.t. ' + colname)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-27T18:05:59.369208Z","iopub.execute_input":"2021-06-27T18:05:59.369733Z","iopub.status.idle":"2021-06-27T18:06:00.060623Z","shell.execute_reply.started":"2021-06-27T18:05:59.369694Z","shell.execute_reply":"2021-06-27T18:06:00.059911Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Clearly, most `females` in 1st `Pclass` with 0 `Parch` and 0 `SibSp` were `Embarked` from `S`. So, we will fill the missing values with `S` below.","metadata":{}},{"cell_type":"code","source":"x_train['Embarked'] = x_train['Embarked'].fillna('S')","metadata":{"execution":{"iopub.status.busy":"2021-06-27T18:06:00.061522Z","iopub.execute_input":"2021-06-27T18:06:00.061898Z","iopub.status.idle":"2021-06-27T18:06:00.065811Z","shell.execute_reply.started":"2021-06-27T18:06:00.061871Z","shell.execute_reply":"2021-06-27T18:06:00.065135Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2.3 The `Fare` feature\n\nThe only missing value for `Fare` exists in `x_test`. Let's have a look:","metadata":{}},{"cell_type":"code","source":"x_test[x_test['Fare'].isnull()]","metadata":{"execution":{"iopub.status.busy":"2021-06-27T18:06:00.068935Z","iopub.execute_input":"2021-06-27T18:06:00.06924Z","iopub.status.idle":"2021-06-27T18:06:00.088003Z","shell.execute_reply.started":"2021-06-27T18:06:00.069213Z","shell.execute_reply":"2021-06-27T18:06:00.086999Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This person is a `male` in the 3rd `Pclass` with no `SibSp` or `Parch`. Since `Fare` is a continuous variable, we will replace the `NaN`value with group median.\n\n**Caution 1:** The group (`males` in the 3rd `Pclass` with no `SibSp` or `Parch`) should be obtained from `x_train`, not `x_test` in order to prevent data leakage.\n\n**Caution 2:** In order the median to be reliable, the group  should contain enough number of data.","metadata":{}},{"cell_type":"code","source":"fare_group = x_train[(x_train['Pclass']==3) & (x_train['Sex']=='male') & (x_train['SibSp']==0) & (x_train['Parch']==0)]\n\nprint('The median is', fare_group['Fare'].median())\nprint('The number of people in this group is', len(fare_group))","metadata":{"execution":{"iopub.status.busy":"2021-06-27T18:06:00.090204Z","iopub.execute_input":"2021-06-27T18:06:00.090794Z","iopub.status.idle":"2021-06-27T18:06:00.102962Z","shell.execute_reply.started":"2021-06-27T18:06:00.090752Z","shell.execute_reply":"2021-06-27T18:06:00.101919Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Since the group is large enough, we can safely replace the missing value with the median.","metadata":{}},{"cell_type":"code","source":"x_test['Fare'] = x_test['Fare'].fillna(fare_group['Fare'].median())","metadata":{"execution":{"iopub.status.busy":"2021-06-27T18:06:00.104998Z","iopub.execute_input":"2021-06-27T18:06:00.105313Z","iopub.status.idle":"2021-06-27T18:06:00.113732Z","shell.execute_reply.started":"2021-06-27T18:06:00.105287Z","shell.execute_reply":"2021-06-27T18:06:00.112864Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2.4 The `Age` feature\n\nAbout 20% of the `Age` column is missing in both `x_train` and `x_test`.\n\nLet's look at how `Age` behaves with respect to `Pclass` and `Sex`.","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(1,2, figsize=(12,5))\nsns.boxplot(y='Age', x='Pclass', data=x_train, ax = ax[0])\nsns.boxplot(y = 'Age', x = 'Sex', data = x_train, ax = ax[1])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-27T18:06:00.115252Z","iopub.execute_input":"2021-06-27T18:06:00.115748Z","iopub.status.idle":"2021-06-27T18:06:00.398435Z","shell.execute_reply.started":"2021-06-27T18:06:00.115709Z","shell.execute_reply":"2021-06-27T18:06:00.397421Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The boxplots above show that passengers in `Pclass` 1 had a higher median age than passengers in `Pclass` 2 or 3. No similar pattern was observed for `Sex`. So, let's impute the missing `Age`s with `Pclass` median value.","metadata":{}},{"cell_type":"code","source":"x_train['Age'] = x_train['Age'].fillna(x_train.groupby('Pclass')['Age'].transform('median'))\nx_test['Age'] = x_test['Age'].fillna(x_train.groupby('Pclass')['Age'].transform('median'))","metadata":{"execution":{"iopub.status.busy":"2021-06-27T18:06:00.399877Z","iopub.execute_input":"2021-06-27T18:06:00.400266Z","iopub.status.idle":"2021-06-27T18:06:00.409057Z","shell.execute_reply.started":"2021-06-27T18:06:00.400226Z","shell.execute_reply":"2021-06-27T18:06:00.408231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2.5 Last check\n\nLet's check our train and test sets for any remaining missing values.","metadata":{}},{"cell_type":"code","source":"print('x_train contains', x_train.isnull().sum().sum(), 'missing values.')\nprint('x_test contains', x_test.isnull().sum().sum(), 'missing values.')","metadata":{"execution":{"iopub.status.busy":"2021-06-27T18:06:00.410446Z","iopub.execute_input":"2021-06-27T18:06:00.410837Z","iopub.status.idle":"2021-06-27T18:06:00.424519Z","shell.execute_reply.started":"2021-06-27T18:06:00.410808Z","shell.execute_reply":"2021-06-27T18:06:00.423655Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"So we are good to go!","metadata":{}},{"cell_type":"markdown","source":"## Section 3: Feature engineering\n\nNow that we have imputed all missing data, let's take a look at the training data again.","metadata":{}},{"cell_type":"code","source":"x_train.sample(5)","metadata":{"execution":{"iopub.status.busy":"2021-06-27T18:06:00.425722Z","iopub.execute_input":"2021-06-27T18:06:00.425977Z","iopub.status.idle":"2021-06-27T18:06:00.451716Z","shell.execute_reply.started":"2021-06-27T18:06:00.425952Z","shell.execute_reply":"2021-06-27T18:06:00.450733Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 3.1 Have family at the ship?\n\nPerhaps an obvious feature should be whether the person have some family at the ship or not. \n\nThis is simply whether the sum of `SibSp` (siblings&spouse) and `Parch` (parents&children) is a positive number of not.","metadata":{}},{"cell_type":"code","source":"x_train['haveFamily'] = (x_train['SibSp'] + x_train['Parch'] > 0)*1 #multipy by 1 to convert True/False to 1/0\nx_test['haveFamily'] = (x_test['SibSp'] + x_test['Parch'] > 0)*1","metadata":{"execution":{"iopub.status.busy":"2021-06-27T18:06:00.452771Z","iopub.execute_input":"2021-06-27T18:06:00.45304Z","iopub.status.idle":"2021-06-27T18:06:00.463751Z","shell.execute_reply.started":"2021-06-27T18:06:00.453015Z","shell.execute_reply":"2021-06-27T18:06:00.462749Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 3.2 Title, please\n\nIn titanic, there were people with very different titles including _Mr, Mrs, Dr, Master, Lady_ and so on.\n\nLet's first extract the titles from the names, then we will look at the frequency of each title.","metadata":{}},{"cell_type":"code","source":"x_train['Title'] = x_train['Name'].map(lambda x: x.split('.')[0].split(' ')[-1])\nx_test['Title'] = x_test['Name'].map(lambda x: x.split('.')[0].split(' ')[-1])","metadata":{"execution":{"iopub.status.busy":"2021-06-27T18:06:00.465362Z","iopub.execute_input":"2021-06-27T18:06:00.465788Z","iopub.status.idle":"2021-06-27T18:06:00.477617Z","shell.execute_reply.started":"2021-06-27T18:06:00.465747Z","shell.execute_reply":"2021-06-27T18:06:00.476635Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('The frequency of each title in x_train:')\npd.DataFrame(x_train['Title'].value_counts()).T","metadata":{"execution":{"iopub.status.busy":"2021-06-27T18:06:00.479856Z","iopub.execute_input":"2021-06-27T18:06:00.480353Z","iopub.status.idle":"2021-06-27T18:06:00.498231Z","shell.execute_reply.started":"2021-06-27T18:06:00.480305Z","shell.execute_reply":"2021-06-27T18:06:00.497455Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('The frequency of each title in x_test:')\npd.DataFrame(x_test['Title'].value_counts()).T","metadata":{"execution":{"iopub.status.busy":"2021-06-27T18:06:00.499255Z","iopub.execute_input":"2021-06-27T18:06:00.499664Z","iopub.status.idle":"2021-06-27T18:06:00.517065Z","shell.execute_reply.started":"2021-06-27T18:06:00.499633Z","shell.execute_reply":"2021-06-27T18:06:00.516072Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We may further want to look at the effect of the title for survival.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(15,4))\nsns.countplot(data=x_train, x='Title', hue=y_train)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-27T18:06:00.518187Z","iopub.execute_input":"2021-06-27T18:06:00.518463Z","iopub.status.idle":"2021-06-27T18:06:00.826783Z","shell.execute_reply.started":"2021-06-27T18:06:00.518439Z","shell.execute_reply":"2021-06-27T18:06:00.82553Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"By looking at the above plot, we can say that if you were a _Mr_ in Titanic, chances are you had died in the ocean. On the other hand, being a _Mrs_ and _Miss_ does not appear to differ. Lastly, we can combine other titles in a title called _other_.","metadata":{}},{"cell_type":"code","source":"def newTitle(title):\n    if title == 'Mr':\n        return 'Mr'\n    elif title in ['Mrs','Miss']:\n        return 'Ms'\n    else:\n        return 'other'","metadata":{"execution":{"iopub.status.busy":"2021-06-27T18:06:00.828106Z","iopub.execute_input":"2021-06-27T18:06:00.828441Z","iopub.status.idle":"2021-06-27T18:06:00.832233Z","shell.execute_reply.started":"2021-06-27T18:06:00.828412Z","shell.execute_reply":"2021-06-27T18:06:00.831558Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train['Title'] = x_train['Title'].map(newTitle)\nx_test['Title'] = x_test['Title'].map(newTitle)","metadata":{"execution":{"iopub.status.busy":"2021-06-27T18:06:00.833067Z","iopub.execute_input":"2021-06-27T18:06:00.833448Z","iopub.status.idle":"2021-06-27T18:06:00.845629Z","shell.execute_reply.started":"2021-06-27T18:06:00.833419Z","shell.execute_reply":"2021-06-27T18:06:00.844944Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 3.3 Thoughts for other features\n\nWe can generate features such as:\n- Do you have a large family? (more than 3 people)\n- Do you have a royal title? (e.g. Sir, but not Dr)\n- Convert the continuous `Fare` feature into ordinal: _cheap, medium_, and _expensive_.\n\nBut since we want this notebook to be introductory, we stop our feature engineering here.","metadata":{}},{"cell_type":"markdown","source":"## Section 4: Feature selection\n\nLet's look at our data once more to drop the useless features.","metadata":{}},{"cell_type":"code","source":"x_train.sample(5)","metadata":{"execution":{"iopub.status.busy":"2021-06-27T18:06:00.846496Z","iopub.execute_input":"2021-06-27T18:06:00.84687Z","iopub.status.idle":"2021-06-27T18:06:00.869201Z","shell.execute_reply.started":"2021-06-27T18:06:00.846843Z","shell.execute_reply":"2021-06-27T18:06:00.868388Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The `PassengerId` and `Ticket` features are useless for our task. Also, we extracted information from `Name` to create the `Title`, and now `Name` also became useless. Let's delete these columns.\n\nBut note that we will need the `PassengerId` of `x_test` for our submission file. So, we store them in a variable before deleting it from `x_test`.","metadata":{}},{"cell_type":"code","source":"x_test_PassengerId = x_test['PassengerId']\nx_train = x_train.drop(['PassengerId','Ticket','Name'], axis=1)\nx_test = x_test.drop(['PassengerId','Ticket','Name'], axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-06-27T18:06:00.870375Z","iopub.execute_input":"2021-06-27T18:06:00.870952Z","iopub.status.idle":"2021-06-27T18:06:00.87895Z","shell.execute_reply.started":"2021-06-27T18:06:00.870913Z","shell.execute_reply":"2021-06-27T18:06:00.878272Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We are not really sure whether `SibSp` or `Parch` will be important for the task, but let's keep them for now.","metadata":{}},{"cell_type":"markdown","source":"## Section 5: Handling categorical features\n\nMost learning algorithms do not support categorical variables. So, we might want to convert them to numerical ones. \n\nThe categorical variables for this task are `Sex`, `Embarked` and `Title`. Since `Sex` contains values from two categories (male&female) one numerical feature will be enough for it (1 for female, 0 for male). For the `Embarked` and `Title` columns, we will use one-hot-encoding with _get_dummies_ function from pandas.","metadata":{}},{"cell_type":"code","source":"x_train['Sex'] = (x_train['Sex'] == 'female')*1\nx_test['Sex'] = (x_test['Sex'] == 'female')*1","metadata":{"execution":{"iopub.status.busy":"2021-06-27T18:06:00.880125Z","iopub.execute_input":"2021-06-27T18:06:00.880717Z","iopub.status.idle":"2021-06-27T18:06:00.892593Z","shell.execute_reply.started":"2021-06-27T18:06:00.880678Z","shell.execute_reply":"2021-06-27T18:06:00.891924Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train = pd.get_dummies(x_train)\nx_test = pd.get_dummies(x_test)","metadata":{"execution":{"iopub.status.busy":"2021-06-27T18:06:00.893678Z","iopub.execute_input":"2021-06-27T18:06:00.894223Z","iopub.status.idle":"2021-06-27T18:06:01.012288Z","shell.execute_reply.started":"2021-06-27T18:06:00.894184Z","shell.execute_reply":"2021-06-27T18:06:01.011547Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train.sample(5)","metadata":{"execution":{"iopub.status.busy":"2021-06-27T18:06:01.013457Z","iopub.execute_input":"2021-06-27T18:06:01.014036Z","iopub.status.idle":"2021-06-27T18:06:01.031034Z","shell.execute_reply.started":"2021-06-27T18:06:01.013978Z","shell.execute_reply":"2021-06-27T18:06:01.030285Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"What a lovely data we ended up with.","metadata":{}},{"cell_type":"markdown","source":"## Section 6: Cross Validation\n\nNow that we have successfully created the feature vectors, it is time to find a good learning algorithm. For this purpose, we will try a bunch of classification algorithms and make a grid search.\n\nBut before feeding the data into the learning algorithm, we will scale the features to the range [0,1] using MinMaxScaler.","metadata":{}},{"cell_type":"code","source":"scaler = MinMaxScaler()\nscaler.fit(x_train)\nx_train_scaled = scaler.transform(x_train)\nx_test_scaled = scaler.transform(x_test)","metadata":{"execution":{"iopub.status.busy":"2021-06-27T18:06:01.032129Z","iopub.execute_input":"2021-06-27T18:06:01.032679Z","iopub.status.idle":"2021-06-27T18:06:01.044171Z","shell.execute_reply.started":"2021-06-27T18:06:01.032639Z","shell.execute_reply":"2021-06-27T18:06:01.043503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 6.1 Classifiers\n\nWe will try a bunch of classifiers for cross validation. We hold the classifiers in a list. I also created another list holding the names of these classifiers.","metadata":{}},{"cell_type":"code","source":"knn = KNeighborsClassifier()\nsvc = SVC()\ndt = DecisionTreeClassifier()\nrf = RandomForestClassifier()\nlda = LinearDiscriminantAnalysis()\nlr = LogisticRegression()\nab = AdaBoostClassifier()\n\nclassifiers = [knn, svc, dt, rf, lda, lr, ab]\nclassifier_names = ['knn', 'svc', 'dt', 'rf', 'lda', 'lr', 'ab']","metadata":{"execution":{"iopub.status.busy":"2021-06-27T18:06:01.045497Z","iopub.execute_input":"2021-06-27T18:06:01.04591Z","iopub.status.idle":"2021-06-27T18:06:01.054616Z","shell.execute_reply.started":"2021-06-27T18:06:01.045871Z","shell.execute_reply":"2021-06-27T18:06:01.053649Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 6.2 Parameters\n\nEach classifer has its own hyperparameters. We hold the hyperparameters for each classifier in a dictionary, and put all of them into a list.","metadata":{}},{"cell_type":"code","source":"knn_params = {'n_neighbors':range(2,12), 'p':[1,2,3]}\nsvc_params = {'C':[.1,.2,.5,1,1.5,2], 'kernel':['rbf','linear','poly']}\ndt_params = {'min_samples_split':[2,4,8,16,32,64]}\nrf_params = {'min_samples_split':[2,4,8,16,32,64], 'n_estimators':[10,20,30,50], 'max_features':[2,4,6,8,10]}\nlda_params = {'solver':['svd','lsqr']}\nlr_params = {'C':[.2,.5,1,2,3]}\nab_params = {'n_estimators':[10,20,30,50], 'learning_rate':[.3,.5,1,1.5]}\n\nparameters = [knn_params, svc_params, dt_params, rf_params, lda_params, lr_params, ab_params]","metadata":{"execution":{"iopub.status.busy":"2021-06-27T18:06:01.056333Z","iopub.execute_input":"2021-06-27T18:06:01.056771Z","iopub.status.idle":"2021-06-27T18:06:01.066846Z","shell.execute_reply.started":"2021-06-27T18:06:01.056724Z","shell.execute_reply":"2021-06-27T18:06:01.066113Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 6.3 Grid search\n\nScikit-learn's `GridSearchCV` function finds the best parameters for a classifier in a parameter grid. Iterating over the classifier, we will find the best hyperparameters.","metadata":{}},{"cell_type":"code","source":"results = {}\n\nfor clf, clf_name, param in zip(tqdm(classifiers), classifier_names, parameters):\n    search = GridSearchCV(clf, param)\n    search.fit(x_train_scaled, y_train)\n    results[clf_name] = [search.best_params_, search.best_score_]\n    \nresults = pd.DataFrame(results).T\nresults.columns = ['Best Parameters', 'Score']","metadata":{"tags":[],"execution":{"iopub.status.busy":"2021-06-27T18:06:01.0681Z","iopub.execute_input":"2021-06-27T18:06:01.068691Z","iopub.status.idle":"2021-06-27T18:06:48.621146Z","shell.execute_reply.started":"2021-06-27T18:06:01.06865Z","shell.execute_reply":"2021-06-27T18:06:48.620453Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results","metadata":{"execution":{"iopub.status.busy":"2021-06-27T18:06:48.623672Z","iopub.execute_input":"2021-06-27T18:06:48.62409Z","iopub.status.idle":"2021-06-27T18:06:48.634901Z","shell.execute_reply.started":"2021-06-27T18:06:48.624047Z","shell.execute_reply":"2021-06-27T18:06:48.633961Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The results show that **Random Forest Classifier** is the best algorithm for our task reaching approximately **84%** accuracy. So, we will use its hyperparameters (found by the GridSearchCV) to make our predictions for submission.","metadata":{}},{"cell_type":"markdown","source":"## Section 7: Predicting `y_test`\n\nThe best hyperparameters were given in `results['Best Parameters']['rf']`. So, use them to create a classifier, and train it on `x_train_scaled`, and predict for `x_test_scaled`.","metadata":{}},{"cell_type":"code","source":"clf = RandomForestClassifier(**results['Best Parameters']['rf'])\nclf.fit(x_train_scaled, y_train)\npredictions = clf.predict(x_test_scaled)","metadata":{"execution":{"iopub.status.busy":"2021-06-27T18:06:48.636777Z","iopub.execute_input":"2021-06-27T18:06:48.637385Z","iopub.status.idle":"2021-06-27T18:06:48.781098Z","shell.execute_reply.started":"2021-06-27T18:06:48.637337Z","shell.execute_reply":"2021-06-27T18:06:48.780239Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.DataFrame(columns = ['PassengerId', 'Survived'])\nsubmission['PassengerId'] = x_test_PassengerId\nsubmission['Survived'] = predictions","metadata":{"execution":{"iopub.status.busy":"2021-06-27T18:06:48.782712Z","iopub.execute_input":"2021-06-27T18:06:48.783091Z","iopub.status.idle":"2021-06-27T18:06:48.792375Z","shell.execute_reply.started":"2021-06-27T18:06:48.783051Z","shell.execute_reply":"2021-06-27T18:06:48.791364Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.to_csv('submission.csv',index = False)","metadata":{"execution":{"iopub.status.busy":"2021-06-27T18:06:48.793731Z","iopub.execute_input":"2021-06-27T18:06:48.794389Z","iopub.status.idle":"2021-06-27T18:06:48.804429Z","shell.execute_reply.started":"2021-06-27T18:06:48.794346Z","shell.execute_reply":"2021-06-27T18:06:48.803362Z"},"trusted":true},"execution_count":null,"outputs":[]}]}